{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishnuKunchur/konnakol-to-text/blob/main/model_tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wxwsvRRaC_d",
        "outputId": "f0ddef06-2ce3-49f3-ed34-7d464e1a0f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# load code and data directory mounted on Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "gdrive_base_path = '/content/drive/MyDrive/konnakol-to-text/'\n",
        "\n",
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import librosa\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsybME1oocoh",
        "outputId": "244139d6-f07c-4de5-9829-e32468a5c5a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 2)) (0.25.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (0.10.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 5)) (4.40.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (2.19.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 7)) (1.28.1)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 8)) (3.0.4)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 9)) (0.4.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 10)) (0.30.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (4.11.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (1.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 5)) (0.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 5)) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 5)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 5)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 5)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 5)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 5)) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 5)) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (3.9.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 7)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 7)) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 7)) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 7)) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 8)) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 8)) (3.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 7)) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 7)) (1.2.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 7)) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 7)) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 7)) (0.14.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (4.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 7)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 7)) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 5)) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 5)) (2.0.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 3)) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r /content/drive/MyDrive/konnakol-to-text/requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Collecting ipywebrtc\n",
            "  Using cached ipywebrtc-0.6.0-py2.py3-none-any.whl (260 kB)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchaudio) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchaudio) (1.3.0)\n",
            "Installing collected packages: ipywebrtc\n",
            "Successfully installed ipywebrtc-0.6.0\n"
          ]
        }
      ],
      "source": [
        "! pip install -r /content/drive/MyDrive/konnakol-to-text/requirements.txt\n",
        "! pip install torchaudio ipywebrtc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAs9ru6r87Yw"
      },
      "source": [
        "FUNCTIONS FOR KONNAKOL TRANSCRIPTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld4Eb2W881z5"
      },
      "outputs": [],
      "source": [
        "def transcribe_konnakol_audio(whisper_model: str, audio_array: np.array, WHISPER_SAMPLING_RATE=16_000):\n",
        "  \"\"\"\n",
        "  convert a konnakol sequence audio array derived from a .wav file (sr = whisper sampling rate)\n",
        "\n",
        "  whisper_model: str, fine-tuned whisper-konnakol model path\n",
        "  audio_array: np.array, audio as array\n",
        "  \"\"\"\n",
        "  # check if cuda device is available\n",
        "  device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "  processor = WhisperProcessor.from_pretrained(whisper_model)\n",
        "  # load model\n",
        "  model = WhisperForConditionalGeneration.from_pretrained(whisper_model)\n",
        "\n",
        "  # enforce english transcription, i.e. prevent output language auto-detection\n",
        "  model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language='english', task='transcribe')\n",
        "  model = model.to(device)\n",
        "  print(f'{whisper_model} load complete on {device}')\n",
        "\n",
        "  # Whisper expects 30s of audio for shortform transcription\n",
        "  if len(audio_array) < 30 * WHISPER_SAMPLING_RATE:\n",
        "      # shortform transcription\n",
        "      input_features = processor(audio_array, sampling_rate=WHISPER_SAMPLING_RATE, return_tensors='pt').input_features\n",
        "  else:\n",
        "      # longform transcription\n",
        "      input_features = processor(audio_array, sampling_rate=WHISPER_SAMPLING_RATE, return_tensors='pt',\n",
        "                              truncation=False, padding='longest', return_attention_mask=True).input_features\n",
        "\n",
        "  input_features = input_features.to(device)\n",
        "  # GENERATION (MODEL INFERENCE)\n",
        "  sta = time()\n",
        "  # generate token ids\n",
        "  print(f'{whisper_model} inference in progress..')\n",
        "  predicted_ids = model.generate(input_features, language='en')\n",
        "  # decode tokens to text\n",
        "  transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "  print(transcription)\n",
        "  end = time()\n",
        "  print(f'inference time: {round(end-sta, 3)}s')\n",
        "  transcription = transcription[0]\n",
        "  return transcription"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B00SI4O5844n"
      },
      "outputs": [],
      "source": [
        "def print_konnakol_sequence(transcription: str, type: str):\n",
        "  \"\"\"\n",
        "  sequence: str, konnakol token sequence\n",
        "  type: str, one of 'prediction' or 'ground'\n",
        "  \"\"\"\n",
        "  assert type in ['prediction', 'groundtruth'], \"only ['prediction', 'groundtruth'] are accepted values for 'type'\"\n",
        "  if type == 'prediction':\n",
        "    print(f'MODEL: {whisper_model}')\n",
        "    print(f'{lesson_audio_filepath} TRANSCRIPTION:\\n\\n**')\n",
        "\n",
        "  elif type == 'groundtruth':\n",
        "    print(f'{lesson_audio_filepath} GROUND TRUTH:\\n\\n**')\n",
        "    transcription = metadata.loc[metadata['file_name'] == '/'.join(lesson_audio_filepath.split('/')[-2:])]['transcription'].values[0]\n",
        "\n",
        "  temp_str = ''\n",
        "  for idx, word in enumerate(transcription.split(' ')):\n",
        "    temp_str += word + ' '\n",
        "    if idx % 5 == 0:\n",
        "      print(f'{temp_str}\\n')\n",
        "      temp_str = ''\n",
        "  print(temp_str)\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeqUakQZ8Xt7"
      },
      "source": [
        "LOAD AND INFER SAMPLES FROM CHAPTER LESSON RECORDINGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoTrFFeAmHYD"
      },
      "outputs": [],
      "source": [
        "# baseline model:\n",
        "# USE ONLY FOR TESTING. REMOVE IN PRODUCTION.\n",
        "# whisper_model = 'openai/whisper-medium'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1FIq3_26mvW"
      },
      "outputs": [],
      "source": [
        "# load konnakol audio to be transcribed: train/test (Chapter-Lesson recordings)\n",
        "whisper_model = f'{gdrive_base_path}/models/whisper-medium-konnakol-test'\n",
        "lesson_audio_filepath = f'{gdrive_base_path}/data/test/ch1_l9.wav'\n",
        "RECORDED_SAMPLING_RATE = 44_100\n",
        "WHISPER_SAMPLING_RATE = 16_000\n",
        "\n",
        "audio_array, _ = librosa.load(lesson_audio_filepath, sr=RECORDED_SAMPLING_RATE)\n",
        "audio_array = librosa.resample(audio_array, orig_sr=RECORDED_SAMPLING_RATE, target_sr=WHISPER_SAMPLING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khja-QQu68Rz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbdcc083-76f8-4419-c553-3f05f12eaad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/konnakol-to-text//models/whisper-medium-konnakol-test load complete on cpu\n",
            "/content/drive/MyDrive/konnakol-to-text//models/whisper-medium-konnakol-test inference in progress..\n",
            "['THA-TAH DHOM KI-TA-THA-KA THA-KA-THA-RI KI-TA-THA-KA THA-LAM DHOM KI-TA-THA-KA THA-KA-THA-RI KI-TA-THA-KA THA-KA-DHOM THA-MTHA-KA THA-KA-THA-RI KI-TA-THA-KA THA-MTHA-KA THA-KA-DHIN THA-KA-THA-RI KI-TA-THA-KA THA-MTHA-KA THA-KA-THA-RI KI-TA-THA-KA THA-MTHA-KA TA-DHOM KI-TA-THA-KA THA-MTHA-KA DHOM KI-TA-THA-KA THA-KA-THA-RI KI-TA-THA-KA THA-MTHA-KA THA-RI KI-TA-THA-KA THA-MTHA-KA THA-KA THA-RI KI-TA-THA-KA THA-RI KI-TA-THA-KA THA-LAM DHOM KI-TA-KI-TA-THA-KA THA-LAM DHOM KI-TA-KI-TA-THA-KA THA-KA-DHOM KI-TA-THA-KA THA-LAM DHOM THA-LAM KI-TA-THA-KA THA-LAM DHOM THA-LAM KI-TA-KI-TA-THA-KA THA-LAM DHOM THA-LAM KI-TA-KI-TA-THA-KA THA-LAM DHOM THA-LAM KI-TA-KI-TA-THA-KA THA-LAM DHOM THA-LAM KI-TA-KI-TA-THA-KATHA-LAM-KA-DHOM KITA-KI-TA-THA-KA THA-KA-THA-RI KI-TA-THA-KA']\n",
            "inference time: 176.474s\n"
          ]
        }
      ],
      "source": [
        "transcription = transcribe_konnakol_audio(whisper_model, audio_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cqMe_pVpDLZ"
      },
      "outputs": [],
      "source": [
        "metadata = pd.read_csv(gdrive_base_path + 'data/metadata.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RL9WMelrUMN",
        "outputId": "516e7184-1612-430f-d8cb-e8ba141ec2e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL: /content/drive/MyDrive/konnakol-to-text//models/whisper-medium-konnakol-test\n",
            "/content/drive/MyDrive/konnakol-to-text//data/test/ch1_l9.wav TRANSCRIPTION:\n",
            "\n",
            "**\n",
            "THA-TAH \n",
            "\n",
            "DHOM KI-TA-THA-KA THA-KA-THA-RI KI-TA-THA-KA THA-LAM \n",
            "\n",
            "DHOM KI-TA-THA-KA THA-KA-THA-RI KI-TA-THA-KA THA-KA-DHOM \n",
            "\n",
            "THA-MTHA-KA THA-KA-THA-RI KI-TA-THA-KA THA-MTHA-KA THA-KA-DHIN \n",
            "\n",
            "THA-KA-THA-RI KI-TA-THA-KA THA-MTHA-KA THA-KA-THA-RI KI-TA-THA-KA \n",
            "\n",
            "THA-MTHA-KA TA-DHOM KI-TA-THA-KA THA-MTHA-KA DHOM \n",
            "\n",
            "KI-TA-THA-KA THA-KA-THA-RI KI-TA-THA-KA THA-MTHA-KA THA-RI \n",
            "\n",
            "KI-TA-THA-KA THA-MTHA-KA THA-KA THA-RI KI-TA-THA-KA \n",
            "\n",
            "THA-RI KI-TA-THA-KA THA-LAM DHOM KI-TA-KI-TA-THA-KA \n",
            "\n",
            "THA-LAM DHOM KI-TA-KI-TA-THA-KA THA-KA-DHOM KI-TA-THA-KA \n",
            "\n",
            "THA-LAM DHOM THA-LAM KI-TA-THA-KA THA-LAM \n",
            "\n",
            "DHOM THA-LAM KI-TA-KI-TA-THA-KA THA-LAM DHOM \n",
            "\n",
            "THA-LAM KI-TA-KI-TA-THA-KA THA-LAM DHOM THA-LAM \n",
            "\n",
            "KI-TA-KI-TA-THA-KA THA-LAM DHOM THA-LAM KI-TA-KI-TA-THA-KATHA-LAM-KA-DHOM \n",
            "\n",
            "KITA-KI-TA-THA-KA THA-KA-THA-RI KI-TA-THA-KA \n"
          ]
        }
      ],
      "source": [
        "print_konnakol_sequence(transcription, type='prediction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkaD8orIrUtW",
        "outputId": "26e01c90-5395-4d97-cadc-b66e58a22d97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/konnakol-to-text//data/test/ch1_l9.wav GROUND TRUTH:\n",
            "\n",
            "**\n",
            "TA \n",
            "\n",
            "DHOM KI-TA-THA-KA THA-KA-THA-RI KI-TA-THA-KA THA \n",
            "\n",
            "LAM DHOM KI-TA-THA-KA THA-KA-THA-RI KI-TA-THA-KA \n",
            "\n",
            "THA KA DHOM THAM THA \n",
            "\n",
            "KA THA-KA-THA-RI KI-TA-THA-KA THAM THA \n",
            "\n",
            "KA THA-KA-DIN-NA THA-KA-THA-RI KI-TA-THA-KA THAM \n",
            "\n",
            "THA KA TA DHOM KI-TA-THA-KA \n",
            "\n",
            "THAM THA KA TA DHOM \n",
            "\n",
            "KI-TA-THA-KA THA-KA-THA-RI KI-TA-THA-KA THAM THA \n",
            "\n",
            "KA THA-KA-THA-RI KI-TA-THA-KA THAM THA \n",
            "\n",
            "KA THA-KA-THA-RI KI-TA-THA-KA THA-KA-THA-RI KI-TA-THA-KA \n",
            "\n",
            "THA-LAM KA-DHOM KI TA KI-TA-THA-KA \n",
            "\n",
            "THA LAM KA DHOM KI \n",
            "\n",
            "TA KI-TA-THA-KA THA-KA-THA-RI KI-TA-THA-KA THA-LAM \n",
            "\n",
            "KA-DHOM THA-LAM KA-DHOM THA-LAM KA-DHOM \n",
            "\n",
            "KI TA KI-TA-THA-KA THA-KA-THA-RI KI-TA-THA-KA \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_konnakol_sequence(transcription, type='groundtruth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2USoDsnD9UxO"
      },
      "source": [
        "**LIVE RECORDING TRANSCRIPTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oMfvEf_rVJK"
      },
      "outputs": [],
      "source": [
        "from ipywebrtc import AudioRecorder, CameraStream\n",
        "import torchaudio\n",
        "from IPython.display import Audio\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107,
          "referenced_widgets": [
            "09ec58d98cb04ae6b085c2fb073d1a4e",
            "329d693b00c04fcbb460c76ce7afa606",
            "fd5341c7c4a54c998d0c4a30077fb091",
            "a540b30d43a34d59a2ad6b8f2a8a6aa4",
            "0d447d51c8b440bf995d9ec3dfd1918e",
            "1b5748ab520d4cf8a58c57769dbe0597"
          ]
        },
        "id": "kaxagZC8rVME",
        "outputId": "55fe8cbe-000b-40fc-fea4-077a44505751"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "AudioRecorder(audio=Audio(value=b'', format='webm'), stream=CameraStream(constraints={'audio': True, 'video': …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09ec58d98cb04ae6b085c2fb073d1a4e"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "camera = CameraStream(constraints={'audio': True, 'video': False})\n",
        "recorder = AudioRecorder(stream=camera)\n",
        "recorder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp-z0s9cdYsG"
      },
      "outputs": [],
      "source": [
        "with open('recording.webm', 'wb') as f:\n",
        "    f.write(recorder.audio.value)\n",
        "!ffmpeg -i recording.webm -ac 1 -f wav file.wav -y -hide_banner -loglevel panic\n",
        "sig, sr = torchaudio.load(\"file.wav\")\n",
        "Audio(data=sig, rate=sr)\n",
        "audio_array = sig.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDl3r6WECg39"
      },
      "outputs": [],
      "source": [
        "# inference model (fine-tuned)\n",
        "whisper_model = f'{gdrive_base_path}/models/whisper-medium-konnakol-test'\n",
        "RECORDED_SAMPLING_RATE = sr\n",
        "WHISPER_SAMPLING_RATE = 16_000\n",
        "audio_array = librosa.resample(audio_array, orig_sr=RECORDED_SAMPLING_RATE, target_sr=WHISPER_SAMPLING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxAI6_dpChbM",
        "outputId": "7b6ebc06-c1e5-4a9d-d030-acfa3ee05b2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/konnakol-to-text//models/whisper-medium-konnakol-test load complete on cpu\n",
            "/content/drive/MyDrive/konnakol-to-text//models/whisper-medium-konnakol-test inference in progress..\n",
            "['THA KI-TA-THA-KA THA KI-TA THA KI-TA-THA-KA THA-TI-KI-TA-THA THA KI-TA-THA-KA THA KI-TA THA KI-TA-THA-KA THA-TI-KI-TA-THA-MA']\n",
            "inference time: 43.429s\n"
          ]
        }
      ],
      "source": [
        "transcription = transcribe_konnakol_audio(whisper_model, audio_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZSLfyejChjF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af87a0f-6ee3-4a29-aef7-774591df6dc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openai/whisper-medium load complete on cpu\n",
            "openai/whisper-medium inference in progress..\n",
            "[' Taki Tata Taka Taki Tata Taki Tata Tiki Tata Taki Tata Taka Taki Tata Tiki Tata']\n",
            "inference time: 32.698s\n"
          ]
        }
      ],
      "source": [
        "# comparison with base openai model:\n",
        "whisper_model_name = 'openai/whisper-medium'\n",
        "#model = WhisperForConditionalGeneration.from_pretrained(whisper_model_name)\n",
        "#processor = WhisperProcessor.from_pretrained(whisper_model_name)\n",
        "#model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language='english', task='transcribe')\n",
        "transcription = transcribe_konnakol_audio(whisper_model=whisper_model_name, audio_array=audio_array)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2Eve/4e9jWGLrsXpllQAg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09ec58d98cb04ae6b085c2fb073d1a4e": {
          "model_module": "jupyter-webrtc",
          "model_name": "AudioRecorderModel",
          "model_module_version": "~0.6.0",
          "state": {
            "_data_src": "blob:https://kjkm8igkyn-496ff2e9c6d22116-0-colab.googleusercontent.com/8c4713db-bd4d-4dfd-bf70-051cbbbdd2c9",
            "_dom_classes": [],
            "_model_module": "jupyter-webrtc",
            "_model_module_version": "~0.6.0",
            "_model_name": "AudioRecorderModel",
            "_view_count": null,
            "_view_module": "jupyter-webrtc",
            "_view_module_version": "~0.6.0",
            "_view_name": "AudioRecorderView",
            "audio": "IPY_MODEL_329d693b00c04fcbb460c76ce7afa606",
            "autosave": false,
            "codecs": "",
            "filename": "record",
            "format": "webm",
            "layout": "IPY_MODEL_fd5341c7c4a54c998d0c4a30077fb091",
            "recording": false,
            "stream": "IPY_MODEL_a540b30d43a34d59a2ad6b8f2a8a6aa4"
          }
        },
        "329d693b00c04fcbb460c76ce7afa606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "AudioModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "AudioModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "AudioView",
            "autoplay": true,
            "controls": true,
            "format": "webm",
            "layout": "IPY_MODEL_0d447d51c8b440bf995d9ec3dfd1918e",
            "loop": true
          }
        },
        "fd5341c7c4a54c998d0c4a30077fb091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a540b30d43a34d59a2ad6b8f2a8a6aa4": {
          "model_module": "jupyter-webrtc",
          "model_name": "CameraStreamModel",
          "model_module_version": "~0.6.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "jupyter-webrtc",
            "_model_module_version": "~0.6.0",
            "_model_name": "CameraStreamModel",
            "_view_count": null,
            "_view_module": "jupyter-webrtc",
            "_view_module_version": "~0.6.0",
            "_view_name": "MediaStreamView",
            "constraints": {
              "audio": true,
              "video": false
            },
            "layout": "IPY_MODEL_1b5748ab520d4cf8a58c57769dbe0597"
          }
        },
        "0d447d51c8b440bf995d9ec3dfd1918e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b5748ab520d4cf8a58c57769dbe0597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}